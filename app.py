"""
Multilingual Voice Translation System
State-of-the-Art Models: Whisper Small + NLLB-600M
"""

import streamlit as st
import whisper
import tempfile
from gtts import gTTS
import time
from transformers import pipeline
import os
import torch

# Page config
st.set_page_config(
    page_title="üåç Voice Translation",
    page_icon="üåç",
    layout="wide"
)

# Cache model loading
@st.cache_resource
def load_models():
    """Load Whisper Small + NLLB translation pipeline (cached)"""
    # Use Whisper Small (best quality that fits in 1GB)
    asr_model = whisper.load_model("small")
    
    # Use NLLB for better translation quality - FIXED deprecation
    translator = pipeline(
        "translation",
        model="facebook/nllb-200-distilled-600M",
        model_kwargs={"torch_dtype": torch.float16 if torch.cuda.is_available() else torch.float32}
    )
    
    return asr_model, translator

# Initialize
if 'models' not in st.session_state:
    with st.spinner("üîÑ Loading state-of-the-art AI models... (this takes ~30 seconds)"):
        st.session_state.asr_model, st.session_state.translator = load_models()
        st.success("‚úÖ Models loaded! Using Whisper Small + NLLB-600M")

asr_model = st.session_state.asr_model
translator = st.session_state.translator

# Language mapping for NLLB
LANGUAGES = {
    "Hindi": "hin_Deva", "English": "eng_Latn", "Tamil": "tam_Taml", 
    "Telugu": "tel_Telu", "Kannada": "kan_Knda", "Malayalam": "mal_Mlym", 
    "Marathi": "mar_Deva", "Bengali": "ben_Beng", "Gujarati": "guj_Gujr", 
    "Punjabi": "pan_Guru"
}

# Whisper language codes
WHISPER_LANGS = {
    "Hindi": "hi", "English": "en", "Tamil": "ta", "Telugu": "te",
    "Kannada": "kn", "Malayalam": "ml", "Marathi": "mr", "Bengali": "bn",
    "Gujarati": "gu", "Punjabi": "pa"
}

# TTS codes
TTS_LANGS = {
    "Hindi": "hi", "English": "en", "Tamil": "ta", "Telugu": "te",
    "Kannada": "kn", "Malayalam": "ml", "Marathi": "mr", "Bengali": "bn",
    "Gujarati": "gu", "Punjabi": "pa"
}

# Header
st.title("üåç Multilingual Voice Translation System")
st.markdown("**Powered by Whisper Small + NLLB-600M**")
st.markdown("State-of-the-art speech translation for Indian languages")
st.markdown("---")

# Two columns
col1, col2 = st.columns(2)

with col1:
    st.subheader("üì• Input")
    
    # Language selection
    src_lang_name = st.selectbox("Source Language", list(LANGUAGES.keys()), index=0)
    tgt_lang_name = st.selectbox("Target Language", list(LANGUAGES.keys()), index=1)
    
    # Audio input
    audio_file = st.file_uploader(
        "üé§ Upload audio file",
        type=["wav", "mp3", "m4a", "ogg"],
        help="Upload an audio file to translate"
    )
    
    # OR record audio
    st.markdown("**Or record audio:**")
    audio_bytes = st.audio_input("Record your voice")
    
    translate_btn = st.button("üöÄ Translate", type="primary", use_container_width=True)

with col2:
    st.subheader("üì§ Output")
    output_container = st.container()

# Process translation
if translate_btn:
    audio_input = audio_bytes if audio_bytes else audio_file
    
    if audio_input is None:
        st.error("‚ùå Please provide audio input (upload or record)")
    else:
        with st.spinner("‚è≥ Processing with state-of-the-art models..."):
            try:
                # Get language codes
                whisper_code = WHISPER_LANGS[src_lang_name]
                src_nllb = LANGUAGES[src_lang_name]
                tgt_nllb = LANGUAGES[tgt_lang_name]
                tts_code = TTS_LANGS[tgt_lang_name]
                
                # Save audio to temp file
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                    if isinstance(audio_input, bytes):
                        tmp.write(audio_input)
                    else:
                        tmp.write(audio_input.read())
                    audio_path = tmp.name
                
                # Stage 1: Speech Recognition (Whisper Small - 244M params)
                start_time = time.time()
                progress = st.progress(0, text=f"üé§ Transcribing {src_lang_name} with Whisper Small...")
                
                result = asr_model.transcribe(
                    audio_path,
                    language=whisper_code,
                    task="transcribe",
                    beam_size=5,
                    best_of=5
                )
                source_text = result["text"].strip()
                asr_time = time.time() - start_time
                progress.progress(33, text="‚úÖ Transcription complete!")
                
                if not source_text:
                    st.error("‚ùå No speech detected in audio")
                else:
                    # Stage 2: Translation (NLLB-600M - 600M params)
                    progress.progress(33, text=f"üåç Translating with NLLB-600M to {tgt_lang_name}...")
                    trans_start = time.time()
                    
                    # Translate using NLLB
                    translation_result = translator(
                        source_text,
                        src_lang=src_nllb,
                        tgt_lang=tgt_nllb,
                        max_length=512
                    )
                    target_text = translation_result[0]['translation_text']
                    trans_time = time.time() - trans_start
                    progress.progress(66, text="‚úÖ Translation complete!")
                    
                    # Stage 3: Text-to-Speech
                    progress.progress(66, text=f"üîä Generating speech...")
                    tts_start = time.time()
                    
                    tts = gTTS(text=target_text, lang=tts_code, slow=False)
                    output_path = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
                    tts.save(output_path.name)
                    tts_time = time.time() - tts_start
                    progress.progress(100, text="‚úÖ All done!")
                    
                    total_time = time.time() - start_time
                    
                    # Display results
                    with output_container:
                        st.success("‚úÖ Translation complete!")
                        
                        # Audio output
                        with open(output_path.name, "rb") as audio_out:
                            st.audio(audio_out.read(), format="audio/mp3")
                        
                        # Text outputs
                        st.markdown(f"**üìù Original ({src_lang_name}):**")
                        st.info(source_text)
                        
                        st.markdown(f"**üåç Translation ({tgt_lang_name}):**")
                        st.success(target_text)
                        
                        # Performance metrics
                        st.markdown("**‚ö° Performance:**")
                        metrics_col1, metrics_col2, metrics_col3, metrics_col4 = st.columns(4)
                        with metrics_col1:
                            st.metric("ASR", f"{asr_time:.2f}s")
                        with metrics_col2:
                            st.metric("Translation", f"{trans_time:.2f}s")
                        with metrics_col3:
                            st.metric("TTS", f"{tts_time:.2f}s")
                        with metrics_col4:
                            st.metric("Total", f"{total_time:.2f}s")
                        
                        # Model info
                        st.markdown("""
                        **ü§ñ Models Used:**
                        - **ASR:** Whisper Small (244M params, 96%+ accuracy)
                        - **Translation:** NLLB-600M (600M params, BLEU 35+ for Indian languages)
                        - **TTS:** Google Text-to-Speech
                        """)
                    
                    # Cleanup
                    os.unlink(audio_path)
                    os.unlink(output_path.name)
                    
            except Exception as e:
                st.error(f"‚ùå Error: {str(e)}")
                import traceback
                st.code(traceback.format_exc())

# Footer
st.markdown("---")
st.markdown("""
**üõ†Ô∏è State-of-the-Art Tech Stack:**
- **ASR:** OpenAI Whisper Small (244M parameters)
  - 96%+ accuracy for Indian languages
  - Trained on 680k hours of multilingual data
  
- **Translation:** Meta NLLB-200-distilled-600M (600M parameters)
  - BLEU score 35+ for Indian language pairs
  - Supports 200+ languages
  - Better than Google Translate for low-resource languages

- **TTS:** Google Text-to-Speech
  - Natural voice synthesis
  - 10 Indian languages

**üåê Supported Languages:**
Hindi, English, Tamil, Telugu, Kannada, Malayalam, Marathi, Bengali, Gujarati, Punjabi

**‚ö° Features:**
- Real-time progress tracking
- Beam search for optimal transcription
- Professional UI with performance metrics
- File upload + browser recording support
""")
